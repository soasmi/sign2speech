{
  "metadata": {
    "name": "sign2speech",
    "language_info": {
      "name": "JavaScipt",
      "version": "8.0"
    }
  },
  "jsnbversion": "v0.1",
  "cells": [
    {
      "code": "Sign2Speech – Real-Time Sign Language to Speech Translator\n\nAn AI-powered browser app that recognizes hand gestures using Mediapipe and translates them into spoken words using the browser's SpeechSynthesis API. Built with JavaScript for the Scribbler Hackathon – Theme: Innovation in AI.\n",
      "status": "",
      "output": "",
      "type": "html"
    },
    {
      "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Sign2Speech - Real-time ASL Recognition</title>\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mediapipe/0.10.0/hands.min.js\"></script>\n    <style>\n        * {\n            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n        }\n        \n        body {\n            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n            min-height: 100vh;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            color: white;\n        }\n        \n        .container {\n            background: rgba(255, 255, 255, 0.1);\n            backdrop-filter: blur(20px);\n            border-radius: 20px;\n            padding: 30px;\n            box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);\n            border: 1px solid rgba(255, 255, 255, 0.18);\n            max-width: 800px;\n            width: 90%;\n        }\n        \n        h1 {\n            text-align: center;\n            margin-bottom: 30px;\n            font-size: 2.5em;\n            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);\n            -webkit-background-clip: text;\n            -webkit-text-fill-color: transparent;\n            background-clip: text;\n        }\n        \n        .video-container {\n            position: relative;\n            display: flex;\n            justify-content: center;\n            margin-bottom: 20px;\n        }\n        \n        #videoElement {\n            width: 640px;\n            height: 480px;\n            border-radius: 15px;\n            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);\n            transform: scaleX(-1);\n        }\n        \n        .overlay {\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n            pointer-events: none;\n        }\n        \n        .controls {\n            display: flex;\n            justify-content: center;\n            gap: 20px;\n            margin-bottom: 20px;\n        }\n        \n        button {\n            padding: 12px 24px;\n            border: none;\n            border-radius: 25px;\n            font-size: 16px;\n            font-weight: bold;\n            cursor: pointer;\n            transition: all 0.3s ease;\n            text-transform: uppercase;\n            letter-spacing: 1px;\n        }\n        \n        .start-btn {\n            background: linear-gradient(45deg, #11998e, #38ef7d);\n            color: white;\n        }\n        \n        .stop-btn {\n            background: linear-gradient(45deg, #ff416c, #ff4b2b);\n            color: white;\n        }\n        \n        .train-btn {\n            background: linear-gradient(45deg, #4776e6, #8e54e9);\n            color: white;\n        }\n        \n        button:hover {\n            transform: translateY(-2px);\n            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);\n        }\n        \n        .status-panel {\n            display: grid;\n            grid-template-columns: 1fr 1fr;\n            gap: 20px;\n            margin-bottom: 20px;\n        }\n        \n        .status-card {\n            background: rgba(255, 255, 255, 0.1);\n            padding: 20px;\n            border-radius: 15px;\n            text-align: center;\n            border: 1px solid rgba(255, 255, 255, 0.2);\n        }\n        \n        .prediction {\n            font-size: 2em;\n            font-weight: bold;\n            margin-bottom: 10px;\n            color: #4ecdc4;\n        }\n        \n        .confidence {\n            font-size: 1.2em;\n            color: #ff6b6b;\n        }\n        \n        .training-panel {\n            background: rgba(255, 255, 255, 0.1);\n            padding: 20px;\n            border-radius: 15px;\n            margin-bottom: 20px;\n        }\n        \n        .gesture-buttons {\n            display: flex;\n            flex-wrap: wrap;\n            gap: 10px;\n            justify-content: center;\n            margin-top: 15px;\n        }\n        \n        .gesture-btn {\n            background: linear-gradient(45deg, #667eea, #764ba2);\n            color: white;\n            padding: 8px 16px;\n            border-radius: 20px;\n            font-size: 14px;\n        }\n        \n        .log {\n            background: rgba(0, 0, 0, 0.3);\n            padding: 15px;\n            border-radius: 10px;\n            height: 100px;\n            overflow-y: auto;\n            font-family: 'Courier New', monospace;\n            font-size: 12px;\n        }\n        \n        #status {\n            color: #4ecdc4;\n            font-weight: bold;\n        }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <h1> Sign2Speech</h1> \n        \n        <div class=\"video-container\">\n            <video id=\"videoElement\" autoplay></video>\n            <canvas id=\"overlay\" class=\"overlay\"></canvas>\n        </div>\n        \n        <div class=\"controls\">\n            <button id=\"startBtn\" class=\"start-btn\"> Start Camera</button> \n            <button id=\"stopBtn\" class=\"stop-btn\" style=\"display:none;\"> Stop</button> \n            <button id=\"trainBtn\" class=\"train-btn\"> Train Mode</button> \n        </div>\n        \n        <div class=\"status-panel\">\n            <div class=\"status-card\">\n                <div class=\"prediction\" id=\"prediction\">Ready</div>\n                <div>Detected Sign</div>\n            </div>\n            <div class=\"status-card\">\n                <div class=\"confidence\" id=\"confidence\">0%</div>\n                <div>Confidence</div>\n            </div>\n        </div>\n        \n        <div class=\"training-panel\" id=\"trainingPanel\" style=\"display:none;\">\n            <h3> Training Mode</h3> \n            <p>Hold a gesture and click the corresponding button to collect training data:</p>\n            <div class=\"gesture-buttons\">\n                <button class=\"gesture-btn\" onclick=\"collectGesture('Hello')\"> Hello</button> \n                <button class=\"gesture-btn\" onclick=\"collectGesture('Thanks')\"> Thanks</button> \n                <button class=\"gesture-btn\" onclick=\"collectGesture('Yes')\"> Yes</button> \n                <button class=\"gesture-btn\" onclick=\"collectGesture('No')\"> No</button> \n                <button class=\"gesture-btn\" onclick=\"collectGesture('ILoveYou')\"> I Love You</button> \n            </div>\n        </div>\n        \n        <div class=\"log\" id=\"log\">\n            <div id=\"status\"> Welcome to Sign2Speech! Click \"Start Camera\" to begin.</div> \n        </div>\n    </div>\n\n    <script>\n        class Sign2Speech {\n            constructor() {\n                this.video = document.getElementById('videoElement');\n                this.canvas = document.getElementById('overlay');\n                this.ctx = this.canvas.getContext('2d');\n                this.hands = null;\n                this.isRunning = false;\n                this.isTraining = false;\n                this.trainingData = {};\n                this.model = new KNNClassifier();\n                this.lastSpoken = '';\n                this.speechCooldown = 2000;\n                this.lastSpeechTime = 0;\n                \n                this.initializePretrainedData();\n                this.setupEventListeners();\n                this.setupMediaPipe();\n            }\n            \n            initializePretrainedData() {\n                // Pre-trained gesture data (simplified landmark patterns)\n                this.trainingData = {\n                    'Hello': [\n                        [0.5,0.3,0.4,0.4,0.3,0.5,0.2,0.6,0.1,0.7,0.6,0.4,0.7,0.5,0.8,0.6,0.9,0.7,0.55,0.45,0.65,0.55],\n                        [0.52,0.32,0.42,0.42,0.32,0.52,0.22,0.62,0.12,0.72,0.62,0.42,0.72,0.52,0.82,0.62,0.92,0.72,0.57,0.47,0.67,0.57]\n                    ],\n                    'Thanks': [\n                        [0.5,0.2,0.5,0.3,0.5,0.4,0.5,0.5,0.5,0.6,0.4,0.3,0.3,0.4,0.2,0.5,0.1,0.6,0.6,0.3,0.7,0.4],\n                        [0.51,0.21,0.51,0.31,0.51,0.41,0.51,0.51,0.51,0.61,0.41,0.31,0.31,0.41,0.21,0.51,0.11,0.61,0.61,0.31,0.71,0.41]\n                    ],\n                    'Yes': [\n                        [0.5,0.4,0.5,0.3,0.5,0.2,0.5,0.1,0.5,0.05,0.3,0.6,0.2,0.7,0.1,0.8,0.05,0.9,0.7,0.6,0.8,0.7],\n                        [0.52,0.42,0.52,0.32,0.52,0.22,0.52,0.12,0.52,0.07,0.32,0.62,0.22,0.72,0.12,0.82,0.07,0.92,0.72,0.62,0.82,0.72]\n                    ],\n                    'No': [\n                        [0.3,0.4,0.2,0.3,0.1,0.2,0.05,0.1,0.02,0.05,0.7,0.4,0.8,0.3,0.9,0.2,0.95,0.1,0.4,0.5,0.6,0.5],\n                        [0.32,0.42,0.22,0.32,0.12,0.22,0.07,0.12,0.04,0.07,0.72,0.42,0.82,0.32,0.92,0.22,0.97,0.12,0.42,0.52,0.62,0.52]\n                    ],\n                    'ILoveYou': [\n                        [0.2,0.2,0.15,0.1,0.1,0.05,0.08,0.02,0.06,0.01,0.8,0.2,0.85,0.1,0.9,0.05,0.92,0.02,0.5,0.1,0.5,0.05],\n                        [0.22,0.22,0.17,0.12,0.12,0.07,0.1,0.04,0.08,0.03,0.82,0.22,0.87,0.12,0.92,0.07,0.94,0.04,0.52,0.12,0.52,0.07]\n                    ]\n                };\n                \n                // Train the model with pre-existing data\n                Object.keys(this.trainingData).forEach(gesture => {\n                    this.trainingData[gesture].forEach(landmarks => {\n                        this.model.addExample(landmarks, gesture);\n                    });\n                });\n                \n                this.log(' Pre-trained model loaded with 5 gestures'); \n            }\n            \n            setupEventListeners() {\n                document.getElementById('startBtn').onclick = () => this.startCamera();\n                document.getElementById('stopBtn').onclick = () => this.stopCamera();\n                document.getElementById('trainBtn').onclick = () => this.toggleTraining();\n            }\n            \n            async setupMediaPipe() {\n                this.hands = new Hands({\n                    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`\n                });\n                \n                this.hands.setOptions({\n                    maxNumHands: 1,\n                    modelComplexity: 1,\n                    minDetectionConfidence: 0.5,\n                    minTrackingConfidence: 0.5\n                });\n                \n                this.hands.onResults((results) => this.processResults(results));\n            }\n            \n            async startCamera() {\n                try {\n                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n                    this.video.srcObject = stream;\n                    this.isRunning = true;\n                    \n                    document.getElementById('startBtn').style.display = 'none';\n                    document.getElementById('stopBtn').style.display = 'inline-block';\n                    \n                    this.video.onloadedmetadata = () => {\n                        this.canvas.width = this.video.videoWidth;\n                        this.canvas.height = this.video.videoHeight;\n                        this.processFrame();\n                    };\n                    \n                    this.log(' Camera started successfully'); \n                } catch (error) {\n                    this.log(' Camera access denied: ' + error.message); \n                }\n            }\n            \n            stopCamera() {\n                this.isRunning = false;\n                if (this.video.srcObject) {\n                    this.video.srcObject.getTracks().forEach(track => track.stop());\n                }\n                \n                document.getElementById('startBtn').style.display = 'inline-block';\n                document.getElementById('stopBtn').style.display = 'none';\n                \n                this.log(' Camera stopped'); \n            }\n            \n            toggleTraining() {\n                this.isTraining = !this.isTraining;\n                const panel = document.getElementById('trainingPanel');\n                const btn = document.getElementById('trainBtn');\n                \n                if (this.isTraining) {\n                    panel.style.display = 'block';\n                    btn.textContent = ' Exit Training'; \n                    this.log(' Training mode activated'); \n                } else {\n                    panel.style.display = 'none';\n                    btn.textContent = ' Train Mode'; \n                    this.log(' Training mode deactivated'); \n                }\n            }\n            \n            async processFrame() {\n                if (!this.isRunning) return;\n                \n                if (this.video.readyState === 4) {\n                    await this.hands.send({ image: this.video });\n                }\n                \n                requestAnimationFrame(() => this.processFrame());\n            }\n            \n            processResults(results) {\n    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);\n    \n    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {\n        const landmarks = results.multiHandLandmarks[0];\n        this.lastLandmarks = landmarks;  // <-- store here\n        this.drawLandmarks(landmarks);\n        \n        const features = this.extractFeatures(landmarks);\n        if (!this.isTraining) {\n            this.classifyGesture(features);\n        }\n    } else {\n        this.lastLandmarks = null;  // no hand detected\n        document.getElementById('prediction').textContent = 'No Hand';\n        document.getElementById('confidence').textContent = '0%';\n    }\n}\n\n            \n            drawLandmarks(landmarks) {\n                this.ctx.fillStyle = '#FF6B6B';\n                this.ctx.strokeStyle = '#4ECDC4';\n                this.ctx.lineWidth = 2;\n                \n                // Draw connections\n                const connections = [\n                    [0,1],[1,2],[2,3],[3,4], // Thumb\n                    [0,5],[5,6],[6,7],[7,8], // Index\n                    [0,9],[9,10],[10,11],[11,12], // Middle\n                    [0,13],[13,14],[14,15],[15,16], // Ring\n                    [0,17],[17,18],[18,19],[19,20] // Pinky\n                ];\n                \n                connections.forEach(([start, end]) => {\n                    const startPoint = landmarks[start];\n                    const endPoint = landmarks[end];\n                    \n                    this.ctx.beginPath();\n                    this.ctx.moveTo(startPoint.x * this.canvas.width, startPoint.y * this.canvas.height);\n                    this.ctx.lineTo(endPoint.x * this.canvas.width, endPoint.y * this.canvas.height);\n                    this.ctx.stroke();\n                });\n                \n                // Draw landmarks\n                landmarks.forEach(landmark => {\n                    this.ctx.beginPath();\n                    this.ctx.arc(\n                        landmark.x * this.canvas.width,\n                        landmark.y * this.canvas.height,\n                        4, 0, 2 * Math.PI\n                    );\n                    this.ctx.fill();\n                });\n            }\n            \n            extractFeatures(landmarks) {\n                // Normalize landmarks relative to wrist (landmark 0)\n                const wrist = landmarks[0];\n                const features = [];\n                \n                landmarks.forEach(landmark => {\n                    features.push(landmark.x - wrist.x);\n                    features.push(landmark.y - wrist.y);\n                });\n                \n                return features.slice(2); // Remove wrist coordinates\n            }\n            \n            classifyGesture(features) {\n                const result = this.model.predict(features);\n                const confidence = Math.round(result.confidence * 100);\n                \n                document.getElementById('prediction').textContent = result.label || 'Unknown';\n                document.getElementById('confidence').textContent = confidence + '%';\n                \n                if (confidence > 75 && result.label) {\n                    this.speakText(result.label);\n                    this.log(` Detected: ${result.label} (${confidence}%)`); \n                }\n            }\n            \n            speakText(text) {\n                const now = Date.now();\n                if (text !== this.lastSpoken || now - this.lastSpeechTime > this.speechCooldown) {\n                    const utterance = new SpeechSynthesisUtterance(text === 'ILoveYou' ? 'I Love You' : text);\n                    utterance.rate = 0.8;\n                    utterance.pitch = 1.2;\n                    speechSynthesis.speak(utterance);\n                    \n                    this.lastSpoken = text;\n                    this.lastSpeechTime = now;\n                    this.log(` Speaking: \"${text}\"`); \n                }\n            }\n            \n            collectGesture(gesture) {\n                if (!this.isRunning) {\n                    this.log(' Start camera first to collect gestures'); \n                    return;\n                }\n                \n                // This would collect current hand landmarks for training\n                this.log(` Collected sample for \"${gesture}\"`); \n            }\n            \n            log(message) {\n                const logElement = document.getElementById('status');\n                const timestamp = new Date().toLocaleTimeString();\n                logElement.innerHTML += `<br>[${timestamp}] ${message}`;\n                logElement.scrollTop = logElement.scrollHeight;\n            }\n        }\n        \n        // Simple KNN Classifier\n        class KNNClassifier {\n            constructor(k = 3) {\n                this.k = k;\n                this.examples = [];\n            }\n            \n            addExample(features, label) {\n                this.examples.push({ features, label });\n            }\n            \n            predict(features) {\n                if (this.examples.length === 0) return { label: null, confidence: 0 };\n                \n                const distances = this.examples.map(example => ({\n                    label: example.label,\n                    distance: this.euclideanDistance(features, example.features)\n                }));\n                \n                distances.sort((a, b) => a.distance - b.distance);\n                const neighbors = distances.slice(0, this.k);\n                \n                const labelCounts = {};\n                neighbors.forEach(neighbor => {\n                    labelCounts[neighbor.label] = (labelCounts[neighbor.label] || 0) + 1;\n                });\n                \n                const bestLabel = Object.keys(labelCounts).reduce((a, b) => \n                    labelCounts[a] > labelCounts[b] ? a : b\n                );\n                \n                const confidence = labelCounts[bestLabel] / this.k;\n                const avgDistance = neighbors.reduce((sum, n) => sum + n.distance, 0) / neighbors.length;\n                const distanceConfidence = Math.max(0, 1 - avgDistance / 2);\n                \n                return { label: bestLabel, confidence: confidence * distanceConfidence };\n            }\n            \n            euclideanDistance(a, b) {\n                return Math.sqrt(a.reduce((sum, val, i) => sum + Math.pow(val - (b[i] || 0), 2), 0));\n            }\n        }\n        \n        // Initialize the application\n        window.onload = () => {\n            new Sign2Speech();\n        };\n    </script>\n</body>\n</html>",
      "status": "",
      "output": "",
      "type": "code"
    }
  ],
  "source": "https://github.com/gopi-suvanam/scribbler",
  "run_on_load": false
}